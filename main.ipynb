{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "Space Debris Detection Pipeline\n",
    "\n",
    "This module implements a complete pipeline for space debris detection using\n",
    "computer vision and deep learning techniques. It handles data generation,\n",
    "preprocessing, augmentation, model training, and evaluation.\n",
    "\"\"\"\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Standard library imports\n",
    "#------------------------------------------------------------------------------\n",
    "import os                      # Operating system interface\n",
    "import re                      # Regular expressions\n",
    "import time                    # Time access and conversions\n",
    "import glob                    # Unix style pathname pattern expansion\n",
    "import random                  # Generate random numbers\n",
    "import shutil                  # High-level file operations\n",
    "import subprocess              # Subprocess management\n",
    "from datetime import datetime  # Date and time handling\n",
    "from pathlib import Path       # Object-oriented filesystem paths\n",
    "from typing import Dict, List, Tuple, Optional, Any  # Type hinting support\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Data manipulation and visualization\n",
    "#------------------------------------------------------------------------------\n",
    "import numpy as np                   # Numerical computing library\n",
    "import pandas as pd                  # Data manipulation and analysis\n",
    "import matplotlib.pyplot as plt      # Plotting library\n",
    "import matplotlib as mpl             # Matplotlib configuration\n",
    "import matplotlib.font_manager as fm # Font management\n",
    "import cv2                           # OpenCV for computer vision operations\n",
    "from mpl_toolkits.mplot3d import Axes3D  # 3D plotting functionality\n",
    "import seaborn as sns                # Statistical data visualization\n",
    "from matplotlib.colors import LinearSegmentedColormap  # Custom colormaps\n",
    "from sklearn.metrics import (        # Metrics for model evaluation\n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay, \n",
    "    classification_report\n",
    ")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Deep learning and model related imports\n",
    "#------------------------------------------------------------------------------\n",
    "import torch                    # PyTorch deep learning framework\n",
    "from ultralytics import YOLO    # YOLO object detection model\n",
    "import wandb                    # Weights & Biases for experiment tracking\n",
    "import albumentations as A      # Image augmentation library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#------------------------------------------------------------------------------\n",
    "# Base directory configurations\n",
    "#------------------------------------------------------------------------------\n",
    "PROJECT_BASE = r\"C:\\Users\\Jai\\Downloads\\Individual Project Folder\"\n",
    "BLENDER_BASE = os.path.join(PROJECT_BASE, \"Blender_Renders\")\n",
    "YOLOV8_BASE = os.path.join(PROJECT_BASE, \"yolov8-project\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Dataset directory structure\n",
    "#------------------------------------------------------------------------------\n",
    "DATASET_BASE = os.path.join(YOLOV8_BASE, \"dataset6\")\n",
    "DEBRIS_DIR = os.path.join(DATASET_BASE, \"Debris\")\n",
    "DEBRIS_SCALED_DIR = os.path.join(DATASET_BASE, \"Debris_Scaled\")\n",
    "DEBRIS_ANNOTATED_DIR = os.path.join(DATASET_BASE, \"Debris_Annotated\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Configuration file paths\n",
    "#------------------------------------------------------------------------------\n",
    "CONFIG_PATH = os.path.join(DEBRIS_SCALED_DIR, \"config_scaled.yaml\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Blender application and script paths\n",
    "#------------------------------------------------------------------------------\n",
    "BLENDER_EXECUTABLE = r\"C:\\Program Files\\Blender Foundation\\Blender 4.2\\blender.exe\"\n",
    "BLEND_FILE = os.path.join(BLENDER_BASE, \"Earth_render\", \"Earth.blend\")\n",
    "BLENDER_SCRIPT = os.path.join(BLENDER_BASE, \"Earth_render\", \"Crash Solution V3.py\")\n",
    "FLAG_FILE = os.path.join(BLENDER_BASE, \"Earth_render\", \"stop_flag.txt\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Blender object coordinate paths\n",
    "#------------------------------------------------------------------------------\n",
    "ORBIT_CONTAINER_COORDINATES = os.path.join(DATASET_BASE, 'orbit_container_coordinates')\n",
    "DEBRIS_TRACKING_CONTAINER_COORDINATES = os.path.join(DATASET_BASE, 'debris_tracking_container_coordinates')\n",
    "CAMERA_CONTAINER_COORDINATES = os.path.join(DATASET_BASE, 'camera_container_coordinates')\n",
    "QUATERNION_COORDINATES = os.path.join(DATASET_BASE, 'debris_orientation_quaternion')\n",
    "EULER_COORDINATES = os.path.join(DATASET_BASE, 'debris_orientation_euler')\n",
    "AUGMENTATION_SUMMARY = os.path.join(DEBRIS_SCALED_DIR, 'Augmentations Summary.txt')\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Python scripts location\n",
    "#------------------------------------------------------------------------------\n",
    "SCRIPTS_DIR = os.path.join(BLENDER_BASE, \"Python Scripts\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# YOLOv8 training configurations\n",
    "#------------------------------------------------------------------------------\n",
    "WANDB_API_KEY = os.getenv('WANDB_API_KEY', \"3a215434bfc6659b2f1ae767e669c8dcf1964a84\")\n",
    "WANDB_PROJECT_NAME = \"yolov8-debris-detection\"\n",
    "MODEL_TYPE = \"yolov8n.pt\"\n",
    "RUN_NUMBER = \"Run 9\"\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# YOLOv-n confusion matrix CSV directories. Directories must be set manually each time. \n",
    "#------------------------------------------------------------------------------\n",
    "CONFUSION_MATRIX_8 = os.path.join(DEBRIS_SCALED_DIR,r'Run 9 yolov8n (Mar-25-2025 , 09-49-56)\\confusion_matrix_raw.csv')\n",
    "CONFUSION_MATRIX_11 = os.path.join(DEBRIS_SCALED_DIR,r'Run 10 yolo11n (Mar-27-2025 , 22-49-30)\\confusion_matrix_raw.csv')\n",
    "CONFUSION_MATRIX_12 = os.path.join(DEBRIS_SCALED_DIR,r'Run 11 yolo12n (Mar-28-2025 , 11-45-29)\\confusion_matrix_raw.csv')\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Directory creation\n",
    "#------------------------------------------------------------------------------\n",
    "os.makedirs(DEBRIS_SCALED_DIR, exist_ok=True)\n",
    "os.makedirs(DEBRIS_ANNOTATED_DIR, exist_ok=True)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Dataset configuration\n",
    "#------------------------------------------------------------------------------\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Image dimensions\n",
    "#------------------------------------------------------------------------------\n",
    "ORIGINAL_SIZE = 1080\n",
    "NEW_SIZE = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#------------------------------------------------------------------------------\n",
    "# Blender Process Management Function\n",
    "#------------------------------------------------------------------------------\n",
    "# Check if the BLENDER_SCRIPT directory has existing .JSON and .txt files. If so, delete them before running this script.\n",
    "\n",
    "def restart_blender(delay: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Continuously runs Blender in background mode to render specified .blend file and execute Python script.\n",
    "    \n",
    "    Args:\n",
    "        delay (int): Time to wait (in seconds) before restarting Blender after closure\n",
    "    \n",
    "    This function is useful for batch rendering or automating rendering tasks with periodic restarts.\n",
    "    It will continue until a stop flag file is created.\n",
    "    \"\"\"\n",
    "    print(\"Starting Blender monitoring script...\")\n",
    "    \n",
    "    while True:\n",
    "        print(\"Starting Blender render process...\")\n",
    "        \n",
    "        #----------------------------------------------------------------------\n",
    "        # Launch Blender process with configuration\n",
    "        #----------------------------------------------------------------------\n",
    "        # Launch Blender in background mode (-b) with specified .blend file and execute Python script\n",
    "        result = subprocess.run(\n",
    "            [BLENDER_EXECUTABLE, \"-b\", BLEND_FILE, \"--python\", BLENDER_SCRIPT]\n",
    "        )\n",
    "        \n",
    "        # Print the return code (0 indicates success, non-zero indicates an error)\n",
    "        print(f\"Blender exited with return code {result.returncode}.\")\n",
    "\n",
    "        #----------------------------------------------------------------------\n",
    "        # Process control and monitoring\n",
    "        #----------------------------------------------------------------------\n",
    "        # Check if the flag file exists, indicating batch number limit reached\n",
    "        if os.path.exists(FLAG_FILE):\n",
    "            print(\"Batch number limit reached. Stopping the monitoring script.\")\n",
    "            break\n",
    "        \n",
    "        # Wait for specified delay before restarting Blender\n",
    "        print(f\"Waiting {delay} seconds before restarting...\")\n",
    "        time.sleep(delay)\n",
    "        \n",
    "        print(\"Restarting Blender...\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Function execution (disabled by default)\n",
    "#------------------------------------------------------------------------------\n",
    "# Uncomment to execute the Blender restart process\n",
    "restart_blender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#------------------------------------------------------------------------------\n",
    "# Dataset Resizing and Scaling Function\n",
    "#------------------------------------------------------------------------------\n",
    "def resize_and_scale_dataset() -> None:\n",
    "    \"\"\"\n",
    "    Resizes images and preserves corresponding labels for all dataset splits.\n",
    "    \n",
    "    This function:\n",
    "    1. Resizes images from original size to new size\n",
    "    2. Converts PNG images to JPG format\n",
    "    3. Copies corresponding label files without modification\n",
    "    4. Creates a configuration file for the scaled dataset\n",
    "    \"\"\"\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Directory Structure Setup\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Define directories structure for original and scaled datasets\n",
    "    original_dirs = {\n",
    "        split: [\n",
    "            os.path.join(DEBRIS_DIR, split, \"images\"), \n",
    "            os.path.join(DEBRIS_DIR, split, \"labels\")\n",
    "        ] for split in SPLITS\n",
    "    }\n",
    "    \n",
    "    scaled_dirs = {\n",
    "        split: [\n",
    "            os.path.join(DEBRIS_SCALED_DIR, split, \"images\"), \n",
    "            os.path.join(DEBRIS_SCALED_DIR, split, \"labels\")\n",
    "        ] for split in SPLITS\n",
    "    }\n",
    "    \n",
    "    # Create output directories if they don't exist\n",
    "    for dirs in scaled_dirs.values():\n",
    "        os.makedirs(dirs[0], exist_ok=True)\n",
    "        os.makedirs(dirs[1], exist_ok=True)\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Image and Label Processing\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Process each dataset split\n",
    "    for split in SPLITS:\n",
    "        image_orig_dir, label_orig_dir = original_dirs[split]\n",
    "        image_scaled_dir, label_scaled_dir = scaled_dirs[split]\n",
    "        \n",
    "        # Process all PNG images in the original directory\n",
    "        for img_path in glob.glob(f\"{image_orig_dir}/*.png\"):\n",
    "            # Resize image and save as JPG\n",
    "            img = cv2.imread(img_path)\n",
    "            resized_img = cv2.resize(img, (NEW_SIZE, NEW_SIZE), interpolation=cv2.INTER_AREA)\n",
    "            output_path = os.path.join(image_scaled_dir, os.path.basename(img_path).replace(\".png\", \".jpg\"))\n",
    "            cv2.imwrite(output_path, resized_img)\n",
    "            print(f\"Processed image: {output_path}\")\n",
    "\n",
    "            # Copy corresponding label file without modification\n",
    "            # (No need to modify YOLO format labels as they use normalized coordinates)\n",
    "            label_filename = os.path.basename(img_path).replace(\".png\", \".txt\")\n",
    "            label_path = os.path.join(label_orig_dir, label_filename)\n",
    "            if os.path.exists(label_path):\n",
    "                shutil.copy(label_path, os.path.join(label_scaled_dir, label_filename))\n",
    "                print(f\"Copied label: {os.path.join(label_scaled_dir, label_filename)}\")\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Configuration File Creation\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Create configuration file for the scaled dataset\n",
    "    config_data = f\"\"\"path: {DEBRIS_SCALED_DIR}\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "nc: 4\n",
    "names:\n",
    "    0: Satellite\n",
    "    1: Envisat\n",
    "    2: Hubble\n",
    "    3: Falcon 9 F&S\n",
    "\"\"\"\n",
    "    \n",
    "    with open(CONFIG_PATH, \"w\") as f:\n",
    "        f.write(config_data)\n",
    "    \n",
    "    print(f\"Config file created at: {CONFIG_PATH}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Function execution (uncomment to run)\n",
    "#------------------------------------------------------------------------------\n",
    "# Uncomment to execute the image scaling process\n",
    "resize_and_scale_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#------------------------------------------------------------------------------\n",
    "# Bounding Box Visualization Function\n",
    "#------------------------------------------------------------------------------\n",
    "def visualize_bounding_boxes() -> None:\n",
    "    \"\"\"\n",
    "    Creates visualization of bounding box annotations by:\n",
    "    1. Reading images and corresponding label files\n",
    "    2. Drawing green bounding boxes based on the YOLO format annotations\n",
    "    3. Adding red cross markers at the center of each bounding box\n",
    "    4. Saving the annotated images to a separate directory\n",
    "    \n",
    "    This helps verify the correctness of annotations visually.\n",
    "    \"\"\"\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Directory Setup\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Create output directory structure for each split\n",
    "    for split in SPLITS:\n",
    "        out_split_dir = os.path.join(DEBRIS_ANNOTATED_DIR, split)\n",
    "        os.makedirs(out_split_dir, exist_ok=True)\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Image Processing Loop\n",
    "    #--------------------------------------------------------------------------\n",
    "    # Process each dataset split\n",
    "    for split in SPLITS:\n",
    "        images_dir = os.path.join(DEBRIS_DIR, split, \"images\")\n",
    "        labels_dir = os.path.join(DEBRIS_DIR, split, \"labels\")\n",
    "        out_split_dir = os.path.join(DEBRIS_ANNOTATED_DIR, split)\n",
    "        \n",
    "        # Process each image in the current split\n",
    "        for filename in os.listdir(images_dir):\n",
    "            # Check if the file is an image\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                image_path = os.path.join(images_dir, filename)\n",
    "                \n",
    "                # Get corresponding label filename\n",
    "                base_name, _ = os.path.splitext(filename)\n",
    "                label_file = os.path.join(labels_dir, base_name + \".txt\")\n",
    "                \n",
    "                #--------------------------------------------------------------\n",
    "                # Image Loading and Processing\n",
    "                #--------------------------------------------------------------\n",
    "                # Read the image\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    print(f\"Error loading image: {image_path}\")\n",
    "                    continue\n",
    "\n",
    "                height, width = image.shape[:2]\n",
    "                \n",
    "                #--------------------------------------------------------------\n",
    "                # Label Processing and Visualization\n",
    "                #--------------------------------------------------------------\n",
    "                # Process the label file if it exists\n",
    "                if os.path.exists(label_file):\n",
    "                    with open(label_file, \"r\") as f:\n",
    "                        for line in f:\n",
    "                            # Parse YOLO format: class x_center y_center width height\n",
    "                            parts = line.strip().split()\n",
    "                            if len(parts) != 5:\n",
    "                                print(f\"Skipping invalid line in {label_file}: {line}\")\n",
    "                                continue\n",
    "                            \n",
    "                            # Convert normalized coordinates to pixel values\n",
    "                            cls, x_center_norm, y_center_norm, w_norm, h_norm = parts\n",
    "                            x_center = int(float(x_center_norm) * width)\n",
    "                            y_center = int(float(y_center_norm) * height)\n",
    "                            box_width = int(float(w_norm) * width)\n",
    "                            box_height = int(float(h_norm) * height)\n",
    "                            \n",
    "                            # Calculate bounding box coordinates\n",
    "                            x_min = int(x_center - box_width / 2)\n",
    "                            y_min = int(y_center - box_height / 2)\n",
    "                            x_max = int(x_center + box_width / 2)\n",
    "                            y_max = int(y_center + box_height / 2)\n",
    "                            \n",
    "                            # Draw green bounding box\n",
    "                            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), \n",
    "                                        color=(0, 255, 0), thickness=1)\n",
    "                            \n",
    "                            # Draw red cross at the center\n",
    "                            cross_size = 5\n",
    "                            cv2.line(image, (x_center - cross_size, y_center), \n",
    "                                    (x_center + cross_size, y_center), \n",
    "                                    color=(0, 0, 255), thickness=1)\n",
    "                            cv2.line(image, (x_center, y_center - cross_size), \n",
    "                                    (x_center, y_center + cross_size), \n",
    "                                    color=(0, 0, 255), thickness=1)\n",
    "                else:\n",
    "                    print(f\"Label file not found for image: {filename}\")\n",
    "                \n",
    "                #--------------------------------------------------------------\n",
    "                # Save Annotated Image\n",
    "                #--------------------------------------------------------------\n",
    "                # Save the processed image with visualizations\n",
    "                output_path = os.path.join(out_split_dir, filename)\n",
    "                cv2.imwrite(output_path, image)\n",
    "                print(f\"Saved annotated image: {output_path}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Function execution (uncomment to run)\n",
    "#------------------------------------------------------------------------------\n",
    "# Uncomment to execute the visualization process\n",
    "visualize_bounding_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ---------------------------------------------------------------------------\n",
    "# Helper Functions to Read Images\n",
    "# ---------------------------------------------------------------------------\n",
    "def reading_image_albumentation(image_path: str) -> np.ndarray:\n",
    "    # Read image in BGR format using OpenCV\n",
    "    read_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    # Convert BGR to RGB because albumentations expects an RGB image\n",
    "    read_image = cv2.cvtColor(read_image, cv2.COLOR_BGR2RGB)\n",
    "    return read_image\n",
    "\n",
    "def reading_image_cv2(image_path: str) -> np.ndarray:\n",
    "    # Read image in BGR format using OpenCV (no conversion needed for cv2-based processing)\n",
    "    read_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    return read_image\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Augmentation Transformations\n",
    "# ---------------------------------------------------------------------------\n",
    "# Gaussian Noise Transform: adds Gaussian noise to an image.\n",
    "Gaussian_Transform = A.GaussNoise(std_range=(0.08,0.08), mean_range=(0,0), p=1.0)\n",
    "    # std_range, mean_range, and p are parameters/arguments of the GaussNoise function.\n",
    "    # std_range: Specifies the variance range for the resulting Gaussian noise.\n",
    "    # mean_range: Specifies the mean value for the noise.\n",
    "    # p: Probability of applying the augmentation (1.0 means always applied).\n",
    "\n",
    "# Random Occlusion Transform: randomly drops rectangular regions in the image.\n",
    "Random_Occlusion_Transform = A.CoarseDropout(\n",
    "    num_holes_range=(5,8),\n",
    "    hole_height_range=(0.05,0.05),\n",
    "    hole_width_range=(0.05,0.05),\n",
    "    fill=(0,0,0),\n",
    "    p=1.0\n",
    ")\n",
    "    # num_holes_range: Number of regions to drop out.\n",
    "    # hole_height_range and hole_width_range: Size of holes, specified as a fraction of image dimensions.\n",
    "    # fill: Color fill for the dropped regions (here, black).\n",
    "\n",
    "# Motion Blur Transform: simulates motion blur effect.\n",
    "Motion_Blur_Transform = A.MotionBlur(\n",
    "    blur_limit=(3,3),\n",
    "    angle_range=(0,360),\n",
    "    direction_range=(-1.0,1.0),\n",
    "    allow_shifted=True,\n",
    "    p=1.0\n",
    ")\n",
    "    # blur_limit: Maximum kernel size for the blur effect.\n",
    "    # angle_range: Possible angles (in degrees) for the motion blur.\n",
    "    # direction_range: Direction control for how the blur extends.\n",
    "    # allow_shifted: If True, allows random offset of the blur kernel.\n",
    "    \n",
    "# Grayscale Transform: converts an image to grayscale.\n",
    "Grayscale_Transform = A.ToGray(p=1.0)\n",
    "\n",
    "# Vignetting Transform: applies a vignette effect using Gaussian kernels.\n",
    "def Vignetting_Transform(image: np.ndarray, strength: float = 0.5) -> np.ndarray:\n",
    "    rows, cols = image.shape[:2]\n",
    "    # Create a Gaussian kernel for columns and rows\n",
    "    X_resultant_kernel = cv2.getGaussianKernel(cols, cols * strength)\n",
    "    Y_resultant_kernel = cv2.getGaussianKernel(rows, rows * strength)\n",
    "    kernel = Y_resultant_kernel * X_resultant_kernel.T\n",
    "    mask = kernel / kernel.max()  # Normalize the mask to keep pixel values in range\n",
    "    vignetting = (image * mask[..., np.newaxis]).astype(np.uint8)\n",
    "    return vignetting\n",
    "\n",
    "# Lens Distortion Transform: simulates lens distortion effects.\n",
    "def Lens_Distortion_Transform(image: np.ndarray, k1: float = -0.6, k2: float = 0.2) -> np.ndarray:\n",
    "    h, w = image.shape[:2]\n",
    "    # Define distortion coefficients and camera matrix\n",
    "    dist_coeffs = np.array([k1, k2, 0, 0, 0])\n",
    "    camera_matrix = np.array([[w, 0, w // 2], [0, h, h // 2], [0, 0, 1]], dtype=\"double\")\n",
    "    distorted = cv2.undistort(image, camera_matrix, dist_coeffs)\n",
    "    return distorted\n",
    "    # k1 and k2 are the first two radial distortion coefficients.\n",
    "    # Negative k1 typically creates a barrel distortion (bulging out), while positive k1 produces pincushion distortion (pinched edges).\n",
    "\n",
    "# Poisson Noise Transform: simulates Poisson noise that is more visible in dark regions.\n",
    "def Poisson_Noise_Transform(image: np.ndarray, scale: float = 0.1) -> np.ndarray:\n",
    "    image = image.astype(np.float32) / 255.0  # Normalize image to [0, 1] range.\n",
    "    noisy = np.random.poisson(image * scale * 255.0) / (scale * 255.0)  # Apply Poisson noise.\n",
    "    noisy = np.clip(noisy * 255.0, 0, 255).astype(np.uint8)\n",
    "    return noisy.astype(np.uint8)  \n",
    "    # Poisson noise effect depends on the image brightness, and lower scale values will result in stronger visible noise.\n",
    "\n",
    "# Cosmic Ray Strikes Transform: simulates random bright spots due to cosmic ray strikes.\n",
    "def Cosmic_Ray_Strikes_Transform(image: np.ndarray, num_strikes: int = 100) -> np.ndarray:\n",
    "    h, w, _ = image.shape  # Get image dimensions; ignore channel count (typically 3 for RGB).\n",
    "    for _ in range(num_strikes):\n",
    "        x, y = np.random.randint(0, w), np.random.randint(0, h)\n",
    "        image = cv2.circle(image, (x, y), radius=np.random.randint(1, 2), \n",
    "                           color=(255, 255, 255), thickness=-1)\n",
    "    return image\n",
    "    # Each loop iteration selects a random coordinate and draws a small white circle to simulate a cosmic ray.\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main Execution\n",
    "# ---------------------------------------------------------------------------\n",
    "# Mapping augmentations to their application function and expected image type.\n",
    "# For albumentations transforms, the type is \"alb\". For custom cv2 functions, the type is \"cv2\".\n",
    "augmentations: Dict[str, Tuple[Any, str]] = {\n",
    "    'gaussian': (Gaussian_Transform, 'alb'),\n",
    "    'occlusion': (Random_Occlusion_Transform, 'alb'),\n",
    "    'motion_blur': (Motion_Blur_Transform, 'alb'),\n",
    "    'grayscale': (Grayscale_Transform, 'alb'),\n",
    "    'vignetting': (Vignetting_Transform, 'cv2'),\n",
    "    'lens_distortion': (Lens_Distortion_Transform, 'cv2'),\n",
    "    'poisson': (Poisson_Noise_Transform, 'cv2'),\n",
    "    'cosmic_rays': (Cosmic_Ray_Strikes_Transform, 'cv2')\n",
    "}\n",
    "\n",
    "def apply_augmentations() -> None:\n",
    "    import time  # Import the time module to measure performance\n",
    "    \n",
    "    # Dictionary to store count for each augmentation\n",
    "    augmentation_counts: Dict[str, int] = {}\n",
    "    \n",
    "    # Dictionary to store total time for each augmentation\n",
    "    augmentation_times: Dict[str, float] = {}\n",
    "    \n",
    "    # Loop through each dataset split (e.g., train, val, test)\n",
    "    # os.listdir(images_dir) returns the list of filenames in the specified directory.\n",
    "    for split in SPLITS:\n",
    "        images_dir = os.path.join(DEBRIS_SCALED_DIR, split, \"images\")\n",
    "        labels_dir = os.path.join(DEBRIS_SCALED_DIR, split, \"labels\")\n",
    "        \n",
    "        # Process each image file in the directory\n",
    "        for filename in os.listdir(images_dir):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.join(images_dir, filename)\n",
    "                \n",
    "                # Randomly select one augmentation from the dictionary\n",
    "                aug_name, (aug_func, img_type) = random.choice(list(augmentations.items()))\n",
    "                \n",
    "                # Increment augmentation count\n",
    "                augmentation_counts[aug_name] = augmentation_counts.get(aug_name, 0) + 1\n",
    "                \n",
    "                # Load the image based on the expected type of the augmentation\n",
    "                if img_type == 'alb':\n",
    "                    image = reading_image_albumentation(image_path)\n",
    "                    \n",
    "                    # Measure the time to apply the augmentation\n",
    "                    start_time = time.time()\n",
    "                    # Apply the albumentations augmentation, which returns a dict with key 'image'\n",
    "                    augmented = aug_func(image=image)\n",
    "                    augmented_image = augmented['image']\n",
    "                    # Record the elapsed time\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    \n",
    "                    # Convert the image back to BGR for saving with cv2\n",
    "                    augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "                else:  # For cv2-based custom functions\n",
    "                    image = reading_image_cv2(image_path)\n",
    "                    \n",
    "                    # Measure the time to apply the augmentation\n",
    "                    start_time = time.time()\n",
    "                    augmented_image = aug_func(image)\n",
    "                    # Record the elapsed time\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                \n",
    "                # Add the elapsed time to the total time for this augmentation\n",
    "                augmentation_times[aug_name] = augmentation_times.get(aug_name, 0) + elapsed_time\n",
    "                \n",
    "                # Create a new filename by appending the augmentation name before the file extension\n",
    "                base, ext = os.path.splitext(filename)\n",
    "                new_filename = f\"{base}_{aug_name}{ext}\"\n",
    "                new_image_path = os.path.join(images_dir, new_filename)\n",
    "                \n",
    "                # Save the augmented image using cv2.imwrite\n",
    "                cv2.imwrite(new_image_path, augmented_image)\n",
    "                \n",
    "                # Handle the associated label file, if it exists:\n",
    "                # Copy the original label file to a new file with an updated name.\n",
    "                original_label = os.path.join(labels_dir, base + \".txt\")\n",
    "                new_label = os.path.join(labels_dir, f\"{base}_{aug_name}.txt\")\n",
    "                if os.path.exists(original_label):\n",
    "                    shutil.copyfile(original_label, new_label)\n",
    "                \n",
    "                print(f\"Augmented {filename} with {aug_name} and saved as {new_filename}\")\n",
    "    \n",
    "    # After processing, print summary of augmentation counts and average times\n",
    "    print(\"\\nAugmentation Summary:\")\n",
    "    for aug, count in augmentation_counts.items():\n",
    "        # Calculate the average time if the augmentation was applied at least once\n",
    "        avg_time = augmentation_times.get(aug, 0) / count if count > 0 else 0\n",
    "        print(f\"  {aug}: {count} image(s) augmented, avg time: {avg_time:.6f} seconds per image\")\n",
    "    \n",
    "    # Print overall average time across all augmentations\n",
    "    total_images = sum(augmentation_counts.values())\n",
    "    total_time = sum(augmentation_times.values())\n",
    "    overall_avg_time = total_time / total_images if total_images > 0 else 0\n",
    "    print(f\"\\nOverall average augmentation time: {overall_avg_time:.6f} seconds per image\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Function Execution\n",
    "# ---------------------------------------------------------------------------\n",
    "# Uncomment the following line to execute the augmentation process.\n",
    "apply_augmentations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ------------------------------------------------------------------------------\n",
    "# Setup and Utility Functions for W&B, GPU, Training, and Logging\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def setup_wandb() -> None:\n",
    "    \"\"\"\n",
    "    Set up Weights & Biases integration with API key.\n",
    "    \n",
    "    - Configures the WANDB_API_KEY as an environment variable.\n",
    "    - Prints project configuration details.\n",
    "    \"\"\"\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "    print(f\"W&B configured with project: {WANDB_PROJECT_NAME}\")\n",
    "\n",
    "\n",
    "def check_gpu_availability() -> None:\n",
    "    \"\"\"\n",
    "    Check and print GPU details:\n",
    "    \n",
    "    - CUDA availability\n",
    "    - Number of GPUs\n",
    "    - GPU device name\n",
    "    - Instructions for finding GPU index via nvidia-smi.\n",
    "    \"\"\"\n",
    "    print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Number of GPUs detected:\", torch.cuda.device_count())\n",
    "        print(\"GPU Name Index 0:\", torch.cuda.get_device_name(0))\n",
    "        print(\"To find GPU Index, use nvidia-smi in command prompt\")\n",
    "    else:\n",
    "        print(\"No GPU available, using CPU\")\n",
    "    \n",
    "    print()  # Empty line for better readability\n",
    "\n",
    "\n",
    "def train_yolov8_model(\n",
    "    epochs: int = 100,\n",
    "    batch_size: int = 16,\n",
    "    image_size: int = 640,\n",
    "    device: int = 0\n",
    ") -> Tuple[YOLO, str]:\n",
    "    \"\"\"\n",
    "    Train a YOLOv8 model with W&B integration.\n",
    "    \n",
    "    Args:\n",
    "        epochs: Number of training epochs.\n",
    "        batch_size: Number of images per batch.\n",
    "        image_size: Input image resolution.\n",
    "        device: GPU device index (0 for first GPU).\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing the trained model and the output directory path.\n",
    "    \"\"\"\n",
    "    global run_name\n",
    "\n",
    "    try:\n",
    "        # Initialize model and display its info\n",
    "        model = YOLO(MODEL_TYPE)\n",
    "        model.info()\n",
    "        print()\n",
    "        \n",
    "        # Create a unique run name with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%b-%d-%Y , %H-%M-%S\")\n",
    "        run_name = f\"{RUN_NUMBER} {os.path.basename(MODEL_TYPE).split('.')[0]} ({timestamp})\"\n",
    "        \n",
    "        # Initialize W&B run with the configured project and unique run name\n",
    "        wandb.init(project=WANDB_PROJECT_NAME, name=run_name)\n",
    "        \n",
    "        print(f\"Starting training with {epochs} epochs, batch size {batch_size}\")\n",
    "        model.train(\n",
    "            data=CONFIG_PATH,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            imgsz=image_size,\n",
    "            batch=batch_size,\n",
    "            project=DEBRIS_SCALED_DIR,\n",
    "            name=run_name,\n",
    "            save_period=5  # Save checkpoint every 5 epochs\n",
    "        )\n",
    "        \n",
    "        # Define run directory based on the unique run name\n",
    "        run_dir = os.path.join(DEBRIS_SCALED_DIR, run_name)\n",
    "        print(f\"Training completed. Results saved to: {run_dir}\")\n",
    "        \n",
    "        return model, run_dir\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {str(e)}\")\n",
    "        wandb.finish()\n",
    "        raise\n",
    "\n",
    "\n",
    "def extract_confusion_matrix(model: YOLO, run_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Extract and save confusion matrix data from model validation.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained YOLO model instance.\n",
    "        run_dir: Directory path for training outputs.\n",
    "    \n",
    "    Saves:\n",
    "        - confusion_matrix_raw.csv: Raw confusion matrix data.\n",
    "        - confusion_matrix_plot.png: Visualization of confusion matrix.\n",
    "    \"\"\"\n",
    "    print(\"Running model validation to extract metrics...\")\n",
    "    \n",
    "    validation_name = f\"{os.path.basename(run_dir)} Validation\"\n",
    "    results = model.val(\n",
    "        save_json=True,\n",
    "        device=0,\n",
    "        project=DEBRIS_SCALED_DIR,\n",
    "        name=validation_name\n",
    "    )\n",
    "    \n",
    "    if hasattr(results, 'confusion_matrix') and results.confusion_matrix is not None:\n",
    "        confusion_matrix = results.confusion_matrix.matrix\n",
    "        \n",
    "        # Convert confusion matrix to numpy array if on GPU (using .cpu())\n",
    "        cm_data = confusion_matrix.cpu().numpy() if hasattr(confusion_matrix, 'cpu') else confusion_matrix\n",
    "        \n",
    "        cm_csv_path = os.path.join(run_dir, \"confusion_matrix_raw.csv\")\n",
    "        pd.DataFrame(cm_data).to_csv(cm_csv_path)\n",
    "        print(f\"Raw confusion matrix data saved to: {cm_csv_path}\")\n",
    "        \n",
    "        # Log raw confusion matrix data to W&B as a table\n",
    "        wandb.log({\"confusion_matrix_raw\": wandb.Table(dataframe=pd.DataFrame(cm_data))})\n",
    "        \n",
    "        # Plot confusion matrix using matplotlib for visualization\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(cm_data, interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        plt.title('Confusion Matrix')\n",
    "        \n",
    "        cm_fig_path = os.path.join(run_dir, \"confusion_matrix_plot.png\")\n",
    "        plt.savefig(cm_fig_path)\n",
    "        plt.close()\n",
    "        \n",
    "        # Log the confusion matrix plot image to W&B\n",
    "        wandb.log({\"confusion_matrix_plot\": wandb.Image(cm_fig_path)})\n",
    "        print(f\"Confusion matrix visualization saved to: {cm_fig_path}\")\n",
    "    else:\n",
    "        print(\"No confusion matrix data available from validation.\")\n",
    "\n",
    "\n",
    "def log_existing_results_to_wandb(results_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Upload existing training results to Weights & Biases.\n",
    "    \n",
    "    Args:\n",
    "        results_dir: Path to directory containing:\n",
    "            - results.csv: Training metrics.\n",
    "            - weights/best.pt: Best model weights.\n",
    "            - results.png: Training results plot.\n",
    "    \"\"\"\n",
    "    print(f\"Uploading existing results from: {results_dir}\")\n",
    "    \n",
    "    if not os.path.exists(results_dir):\n",
    "        print(f\"Directory not found: {results_dir}\")\n",
    "        return\n",
    "    \n",
    "    csv_path = os.path.join(results_dir, \"results.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Results CSV not found at {csv_path}\")\n",
    "        return\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Update W&B configuration with source file and the number of epochs (rows in CSV)\n",
    "    wandb.config.update({\n",
    "        \"source_file\": csv_path,\n",
    "        \"epochs\": len(df)\n",
    "    })\n",
    "    \n",
    "    # Log each epoch's metrics to W&B\n",
    "    for index, row in df.iterrows():\n",
    "        epoch = index + 1\n",
    "        metrics = row.to_dict()\n",
    "        wandb.log(metrics, step=epoch)\n",
    "    \n",
    "    # Log best model weights as a W&B artifact if available\n",
    "    model_path = os.path.join(results_dir, \"weights\", \"best.pt\")\n",
    "    if os.path.exists(model_path):\n",
    "        artifact = wandb.Artifact(\"best_model\", type=\"model\")\n",
    "        artifact.add_file(model_path)\n",
    "        wandb.log_artifact(artifact)\n",
    "        print(\"Model artifact logged.\")\n",
    "    \n",
    "    # Log training results plot to W&B if exists\n",
    "    results_plot_path = os.path.join(results_dir, \"results.png\")\n",
    "    if os.path.exists(results_plot_path):\n",
    "        wandb.log({\"training_results\": wandb.Image(results_plot_path)})\n",
    "        print(\"Results plot logged.\")\n",
    "\n",
    "    print(\"Existing results successfully uploaded to W&B.\")\n",
    "\n",
    "\n",
    "def train_and_log_model(epochs: int = 100, batch_size: int = 16) -> None:\n",
    "    \"\"\"\n",
    "    Complete pipeline for YOLOv8 model training with W&B integration.\n",
    "    \n",
    "    Args:\n",
    "        epochs: Number of training epochs.\n",
    "        batch_size: Batch size for training.\n",
    "    \"\"\"\n",
    "    # Setup W&B and check for GPU availability\n",
    "    setup_wandb()\n",
    "    check_gpu_availability()\n",
    "    \n",
    "    # Train the YOLOv8 model and obtain the run directory\n",
    "    model, run_dir = train_yolov8_model(epochs=epochs, batch_size=batch_size)\n",
    "    # Extract and log the confusion matrix from model validation\n",
    "    extract_confusion_matrix(model, run_dir)\n",
    "    # Log existing results (CSV, plot, and best model artifact) to W&B\n",
    "    log_existing_results_to_wandb(run_dir)\n",
    "    \n",
    "    # Finalize the W&B run\n",
    "    wandb.finish()\n",
    "    print(\"Training and logging completed successfully.\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Function Execution\n",
    "# ------------------------------------------------------------------------------\n",
    "# Uncomment the following line to execute the training process.\n",
    "train_and_log_model(epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ------------------------------------------------------------------------------\n",
    "# Inference Function for YOLOv8 Model\n",
    "# ------------------------------------------------------------------------------\n",
    "def run_inference(model_weight_path: Optional[str] = None, confidence_threshold: float = 0.80) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Perform inference using a trained YOLOv8 model on test images.\n",
    "    \n",
    "    Args:\n",
    "        model_weight_path: Path to model weights. If None, uses a predefined path.\n",
    "        confidence_threshold: Confidence threshold for detections (0-1).\n",
    "    \n",
    "    Returns:\n",
    "        List of results from the model inference.\n",
    "        \n",
    "    Creates timestamped results in the inference directory.\n",
    "    \"\"\"\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Create a Timestamped Run Name\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Generate a timestamp for the current inference run to keep outputs unique.\n",
    "    datetime_today = datetime.now().strftime(\"%b-%d-%Y , %H-%M-%S\")\n",
    "    model_name = f\"Inference {RUN_NUMBER} {MODEL_TYPE.replace(\".pt\",\"_best_weights\")} ({datetime_today})\"\n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "    # Setup Directories\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Define the directory containing test images and create an output directory for inference results.\n",
    "    test_images_dir = os.path.join(DEBRIS_SCALED_DIR, \"test\", \"images\")\n",
    "    # test_image_dir = r\"C:\\Users\\Jai\\Downloads\\Individual Project Folder\\yolov8-project\\dataset6\\Debris_Scaled\\test\\images\\Hubble_Real_Life_2.jpg\"\n",
    "\n",
    "    inference_output_dir = os.path.join(DEBRIS_SCALED_DIR, \"test\", \"images\", \"inference\")\n",
    "    os.makedirs(inference_output_dir, exist_ok=True)\n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "    # Determine the Model Weight Path\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Use the provided model path or default to a specific run's best weights.\n",
    "    if model_weight_path is None:\n",
    "        model_weight_path = os.path.join(\n",
    "            DEBRIS_SCALED_DIR, \n",
    "            \"Run 9 yolov8n (Mar-25-2025 , 09-49-56)\", \n",
    "            \"weights\", \n",
    "            \"best.pt\"\n",
    "        )\n",
    "    \n",
    "    print(f\"Loading model from: {model_weight_path}\")\n",
    "    model = YOLO(model_weight_path)\n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "    # Run Inference\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Execute the inference process on all images in the test directory.\n",
    "    print(f\"Running inference on images in: {test_images_dir}\")\n",
    "    results = model(\n",
    "        source=test_images_dir, \n",
    "        show=False, \n",
    "        conf=confidence_threshold, \n",
    "        save=True, \n",
    "        project=inference_output_dir, \n",
    "        device=0, \n",
    "        save_conf=True,\n",
    "        show_labels=True, \n",
    "        show_boxes=True, \n",
    "        show_conf=True,\n",
    "        name=model_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Inference completed. Results saved to: {os.path.join(inference_output_dir, model_name)}\")\n",
    "    return results\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Function Execution\n",
    "# ------------------------------------------------------------------------------\n",
    "# Uncomment the following line to execute the inference process\n",
    "run_inference(confidence_threshold=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ============================================================\n",
    "# SET UP MATPLOTLIB CONFIGURATION & FONT\n",
    "# ============================================================\n",
    "# Specify full path to the Lato font file and add it\n",
    "lato_regular_path = r\"C:\\Users\\Jai\\OneDrive - The University of Manchester\\DESIGN\\FONTS\\Lato-Regular.ttf\"\n",
    "lato_bold_path = r\"C:\\Users\\Jai\\OneDrive - The University of Manchester\\DESIGN\\FONTS\\Lato-Bold.ttf\"\n",
    "lato_italic_path = r\"C:\\Users\\Jai\\OneDrive - The University of Manchester\\DESIGN\\FONTS\\Lato-Italic.ttf\"\n",
    "\n",
    "fm.fontManager.addfont(lato_regular_path)\n",
    "fm.fontManager.addfont(lato_bold_path)\n",
    "fm.fontManager.addfont(lato_italic_path)\n",
    "\n",
    "mpl.rcParams['font.family'] = 'sans-serif'\n",
    "mpl.rcParams['font.sans-serif'] = ['Lato']\n",
    "\n",
    "# ============================================================\n",
    "# UTILITY FUNCTION\n",
    "# ============================================================\n",
    "def save_to_csv(folder_path: str, filename: str, data_dict: Dict[str, List]) -> None:\n",
    "    \"\"\"\n",
    "    Save data from a dictionary to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Directory where the CSV will be saved.\n",
    "        filename (str): Name of the CSV file.\n",
    "        data_dict (dict): Dictionary with keys as column headers and values as data lists.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    csv_path = os.path.join(folder_path, filename)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Data saved to: {csv_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# DATA LOADING FUNCTIONS\n",
    "# ============================================================\n",
    "def load_coordinates(folder_path: str) -> Tuple[List[float], List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Load 3D coordinates from .txt files in the given folder.\n",
    "    \n",
    "    Each file should contain at least three numbers (X, Y, Z). If there are extra\n",
    "    tokens, the last three are used as coordinates.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Directory containing the .txt files.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Lists of x, y, and z coordinate values.\n",
    "    \"\"\"\n",
    "    x_vals, y_vals, z_vals = [], [], []\n",
    "    file_count = 0\n",
    "    parsed_count = 0\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_count += 1\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    content = f.read().strip()\n",
    "                    tokens = content.split()\n",
    "                    if len(tokens) >= 3:\n",
    "                        # Use the last three tokens as coordinates\n",
    "                        x = float(tokens[-3])\n",
    "                        y = float(tokens[-2])\n",
    "                        z = float(tokens[-1])\n",
    "                        x_vals.append(x)\n",
    "                        y_vals.append(y)\n",
    "                        z_vals.append(z)\n",
    "                        parsed_count += 1\n",
    "                        # Print the first few parsed coordinates for debugging\n",
    "                        if parsed_count <= 3:\n",
    "                            print(f\"Parsed {file_name}: {x}, {y}, {z}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_name}: {e}\")\n",
    "    \n",
    "    print(f\"Total coordinate files found: {file_count}\")\n",
    "    print(f\"Successfully parsed coordinates: {parsed_count}\")\n",
    "\n",
    "    save_to_csv(folder_path, \"coordinates.csv\", {\"x\": x_vals, \"y\": y_vals, \"z\": z_vals})\n",
    "    return x_vals, y_vals, z_vals\n",
    "\n",
    "def load_debris_quaternion_coordinates(folder_path: str) -> Tuple[List[float], List[float], List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Load quaternions from .txt files in the given folder.\n",
    "    \n",
    "    Each file should contain at least four numbers (W, X, Y, Z). If there are extra\n",
    "    tokens, the last four are used as coordinates.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Directory containing the .txt files.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Lists of w, x, y, and z Quaternion values.\n",
    "    \"\"\"\n",
    "    w_vals, x_vals, y_vals, z_vals = [], [], [], []\n",
    "    file_count = 0\n",
    "    parsed_count = 0\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_count += 1\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    content = f.read().strip()\n",
    "                    tokens = content.split()\n",
    "                    if len(tokens) >= 4:\n",
    "                        # Use the last four tokens as coordinates\n",
    "                        w = float(tokens[-4])\n",
    "                        x = float(tokens[-3])\n",
    "                        y = float(tokens[-2])\n",
    "                        z = float(tokens[-1])\n",
    "                        \n",
    "                        w_vals.append(w)\n",
    "                        x_vals.append(x)\n",
    "                        y_vals.append(y)\n",
    "                        z_vals.append(z)\n",
    "\n",
    "                        parsed_count += 1\n",
    "                        # Print the first few parsed coordinates for debugging\n",
    "                        if parsed_count <= 3:\n",
    "                            print(f\"Parsed {file_name}: {w}, {x}, {y}, {z}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_name}: {e}\")\n",
    "    \n",
    "    print(f\"Total quaternion files found: {file_count}\")\n",
    "    print(f\"Successfully parsed quaternions: {parsed_count}\")\n",
    "\n",
    "    save_to_csv(folder_path, \"debris_quaternion.csv\", {\"w\": w_vals, \"x\": x_vals, \"y\": y_vals, \"z\": z_vals})\n",
    "    return w_vals, x_vals, y_vals, z_vals\n",
    "\n",
    "def load_offset_values(folder_path: str) -> Tuple[List[int], List[float]]:\n",
    "    \"\"\"\n",
    "    Load offset values from .txt files in the provided folder.\n",
    "    \n",
    "    Frame numbers are extracted from the filenames (first number) and the file content\n",
    "    is expected to contain a single offset value.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Directory with offset .txt files.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Sorted lists of frames and their corresponding offset values.\n",
    "    \"\"\"\n",
    "    offsets = {}\n",
    "    file_count = 0\n",
    "    parsed_count = 0\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_count += 1\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # Extract the first number from the filename as the frame number\n",
    "                match = re.search(r'(\\d+)', file_name)\n",
    "                if match:\n",
    "                    frame_num = int(match.group(0))\n",
    "                    with open(file_path, \"r\") as f:\n",
    "                        content = f.read().strip()\n",
    "                        offset = float(content)\n",
    "                        offsets[frame_num] = offset\n",
    "                        parsed_count += 1\n",
    "                        if parsed_count <= 3:\n",
    "                            print(f\"Parsed {file_name}: Frame {frame_num} offset {offset}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing offset file {file_name}: {e}\")\n",
    "    \n",
    "    print(f\"Total offset files found: {file_count}\")\n",
    "    print(f\"Successfully parsed offsets: {parsed_count}\")\n",
    "\n",
    "    # Sort results by frame number\n",
    "    sorted_frames = sorted(offsets.keys())\n",
    "    sorted_offsets = [offsets[frame] for frame in sorted_frames]\n",
    "\n",
    "    save_to_csv(folder_path, \"offsets.csv\", {\"frame\": sorted_frames, \"offset\": sorted_offsets})\n",
    "    return sorted_frames, sorted_offsets\n",
    "\n",
    "# ============================================================\n",
    "# PLOTTING FUNCTIONS\n",
    "# ============================================================\n",
    "def plot_3d_scatter(x_vals: List[float], y_vals: List[float], z_vals: List[float], \n",
    "                    title: str = 'Debris Coordinates', marker_size: int = 20, \n",
    "                    alpha: float = 0.7) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create a 3D scatter plot of the provided coordinates.\n",
    "    \n",
    "    Args:\n",
    "        x_vals (list): List of x coordinate values.\n",
    "        y_vals (list): List of y coordinate values.\n",
    "        z_vals (list): List of z coordinate values.\n",
    "        title (str): Title of the plot.\n",
    "        marker_size (int): Size of the markers.\n",
    "        alpha (float): Transparency level of the markers.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: Figure containing the 3D scatter plot.\n",
    "    \"\"\"\n",
    "    BG_IMAGE = plt.imread(r\"C:\\Users\\Jai\\Downloads\\Individual Project Folder\\yolov8-project\\dataset6\\BG_IMAGE2.png\")\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Create background axes that span the entire figure and display the image\n",
    "    ax_bg = fig.add_axes([0, 0, 1, 1])\n",
    "    ax_bg.imshow(BG_IMAGE, aspect='auto')\n",
    "    ax_bg.axis('off')\n",
    "\n",
    "    ax = fig.add_axes([0.05, 0.05, 0.9, 0.9], projection='3d')\n",
    "    ax.patch.set_alpha(0.0)\n",
    "    ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "    ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "    ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "    # Plot scatter points with black edges for better visibility\n",
    "    ax.scatter(x_vals, y_vals, z_vals, c='gray', s=marker_size, alpha=alpha, edgecolors='k')\n",
    "\n",
    "    # Set axis labels and plot title\n",
    "    ax.set_xlabel('X', labelpad=10, fontsize=20, fontweight='bold', color='black')\n",
    "    ax.set_ylabel('Y', labelpad=10, fontsize=20, fontweight='bold', color='black')\n",
    "    ax.set_zlabel('Z', labelpad=10, fontsize=20, fontweight='bold', color='black')\n",
    "    ax.set_title(title, pad=0, fontsize=34, color='black', fontstyle='italic')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Set equal aspect ratio for all axes\n",
    "    max_range = np.array([max(x_vals)-min(x_vals), max(y_vals)-min(y_vals), max(z_vals)-min(z_vals)]).max() / 2.0\n",
    "    mid_x = (max(x_vals) + min(x_vals)) * 0.5\n",
    "    mid_y = (max(y_vals) + min(y_vals)) * 0.5\n",
    "    mid_z = (max(z_vals) + min(z_vals)) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    # Make tick labels bold \n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    for label in ax.get_zticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "\n",
    "    return fig\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def plot_3d_quaternion_scatter(w_vals: List[float], x_vals: List[float], \n",
    "                              y_vals: List[float], z_vals: List[float], \n",
    "                              title: str = '3D Quaternion Scatter', \n",
    "                              marker_size: int = 20, alpha: float = 0.7) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create a 3D scatter plot of quaternion orientations.\n",
    "    \n",
    "    Args:\n",
    "        w_vals (list): List of w quaternion values.\n",
    "        x_vals (list): List of x quaternion values.\n",
    "        y_vals (list): List of y quaternion values.\n",
    "        z_vals (list): List of z quaternion values.\n",
    "        title (str): Title of the plot.\n",
    "        marker_size (int): Size of the markers.\n",
    "        alpha (float): Transparency level of the markers.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: Figure containing the 3D scatter plot.\n",
    "    \"\"\"\n",
    "    BG_IMAGE = plt.imread(r\"C:\\Users\\Jai\\Downloads\\Individual Project Folder\\yolov8-project\\dataset6\\BG_IMAGE2.png\")\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Create background axes that span the entire figure and display the image\n",
    "    ax_bg = fig.add_axes([0, 0, 1, 1])\n",
    "    ax_bg.imshow(BG_IMAGE, aspect='auto')\n",
    "    ax_bg.axis('off')\n",
    "\n",
    "    # Create 3D plot\n",
    "    ax = fig.add_axes([0.05, 0.05, 0.9, 0.9], projection='3d')\n",
    "    ax.patch.set_alpha(0.0)\n",
    "    ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "    ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "    ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "\n",
    "    # Convert quaternions to rotation vectors (for visualization)\n",
    "    quaternions = np.column_stack((w_vals, x_vals, y_vals, z_vals))\n",
    "    rotation_vectors = R.from_quat(quaternions).as_rotvec()\n",
    "    \n",
    "    # Extract X, Y, Z components\n",
    "    x, y, z = rotation_vectors[:, 0], rotation_vectors[:, 1], rotation_vectors[:, 2]\n",
    "\n",
    "    # Plot scatter points with black edges for better visibility\n",
    "    ax.scatter(x, y, z, c='gray', s=marker_size, alpha=alpha, edgecolors='k')\n",
    "\n",
    "    # Set axis labels and plot title\n",
    "    ax.set_xlabel('X', labelpad=10, fontsize=20, fontweight='bold', color='black')\n",
    "    ax.set_ylabel('Y', labelpad=10, fontsize=20, fontweight='bold', color='black')\n",
    "    ax.set_zlabel('Z', labelpad=10, fontsize=20, fontweight='bold', color='black')\n",
    "    ax.set_title(title, pad=1, fontsize=34, color='black', fontstyle='italic')\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Set equal aspect ratio for all axes\n",
    "    max_range = np.array([max(x)-min(x), max(y)-min(y), max(z)-min(z)]).max() / 2.0\n",
    "    mid_x = (max(x) + min(x)) * 0.5\n",
    "    mid_y = (max(y) + min(y)) * 0.5\n",
    "    mid_z = (max(z) + min(z)) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    # Make tick labels bold \n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    for label in ax.get_zticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "\n",
    "    return fig\n",
    "\n",
    "def plot_euler_angle_scatter(roll_vals: List[float], pitch_vals: List[float], yaw_vals: List[float], \n",
    "                            title: str = 'Scatter Plot of Euler Angles', \n",
    "                            marker_size: int = 20, alpha: float = 0.7) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create a 2D scatter plot for Roll vs Pitch, Roll vs Yaw, and Pitch vs Yaw,\n",
    "    with a background image behind the main plot.\n",
    "\n",
    "    Args:\n",
    "        roll_vals (list): List of Roll values.\n",
    "        pitch_vals (list): List of Pitch values.\n",
    "        yaw_vals (list): List of Yaw values.\n",
    "        title (str): Title of the plot.\n",
    "        marker_size (int): Size of the markers.\n",
    "        alpha (float): Transparency level of the markers.\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: Figure containing the 2D scatter plot.\n",
    "    \"\"\"\n",
    "    BG_IMAGE = plt.imread(r\"C:\\Users\\Jai\\Downloads\\Individual Project Folder\\yolov8-project\\dataset6\\BG_IMAGE2.png\")\n",
    "\n",
    "    # Create the figure (no default axes yet)\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # --- Background Axes ---\n",
    "    # Spans the entire figure; placed behind the main axis (zorder=0).\n",
    "    ax_bg = fig.add_axes([0, 0, 1, 1], zorder=0)\n",
    "    ax_bg.imshow(BG_IMAGE, aspect='auto')\n",
    "    ax_bg.axis('off')  # Hide ticks on the background axis\n",
    "\n",
    "    # --- Main Plot Axes ---\n",
    "    # Add the main axis on top (zorder=1)\n",
    "    ax = fig.add_subplot(111, zorder=1)\n",
    "    ax.set_facecolor('white')  # Transparent so background is visible\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.6, alpha=0.7)\n",
    "\n",
    "    # Scatter plots with different colors and markers\n",
    "    ax.scatter(roll_vals, pitch_vals, c='red', alpha=alpha, marker='x', \n",
    "               s=marker_size, label=\"Roll vs Pitch\")\n",
    "    ax.scatter(roll_vals, yaw_vals, c='green', alpha=alpha, marker='x', \n",
    "               s=marker_size, label=\"Roll vs Yaw\")\n",
    "    ax.scatter(pitch_vals, yaw_vals, c='blue', alpha=alpha, marker='^', \n",
    "               s=marker_size, label=\"Pitch vs Yaw\")\n",
    "\n",
    "    # Set axis labels and plot title\n",
    "    ax.set_xlabel(\"Angle (radians)\", fontsize=20, fontweight=\"bold\", color=\"black\")\n",
    "    ax.set_ylabel(\"Angle (radians)\", fontsize=20, fontweight=\"bold\", color=\"black\")\n",
    "    ax.set_title(title, va='bottom', fontsize=34, color=\"black\", fontweight=\"bold\", pad=15, fontstyle='italic')\n",
    "\n",
    "    # Legend\n",
    "    ax.legend(fontsize=12, loc=\"upper right\")\n",
    "\n",
    "    # Make tick labels bold\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontweight(\"bold\")\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontweight(\"bold\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "def plot_offset_values(frames: List[int], offsets: List[float], title: str = 'Offset Values', \n",
    "                      color: str = 'gray', xlabel: str = \"Enter Axis Title\", \n",
    "                      ylabel: str = \"Enter Axis Title\") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create a polar plot of offset values against frame numbers.\n",
    "    \n",
    "    Frame numbers are normalized to angles over a full circle (0 to 2π).\n",
    "    The radial axis shows the offset values, and a box is drawn around the plot area.\n",
    "    \n",
    "    Args:\n",
    "        frames (list): List of frame numbers.\n",
    "        offsets (list): List of corresponding offset values.\n",
    "        title (str): Plot title.\n",
    "        color (str): Color for the markers.\n",
    "        xlabel (str): Label for the x-axis.\n",
    "        ylabel (str): Label for the y-axis.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: Figure containing the polar plot.\n",
    "    \"\"\"\n",
    "    COLOR_BG = 'white'\n",
    "    COLOR_ANGULAR_AXIS_LABELS = 'black'\n",
    "    COLOR_RADIAL_AXIS_LABELS = 'black'\n",
    "    COLOR_AXIS_TITLE = 'black'\n",
    "    COLOR_TITLE = 'black'\n",
    "    BG_IMAGE = plt.imread(r\"C:\\Users\\Jai\\Downloads\\Individual Project Folder\\yolov8-project\\dataset6\\BG_IMAGE2.png\")\n",
    "\n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    # Create background axes that span the entire figure and display the image\n",
    "    ax_bg = fig.add_axes([0, 0, 1, 1])\n",
    "    ax_bg.imshow(BG_IMAGE, aspect='auto')\n",
    "    ax_bg.axis('off')\n",
    "\n",
    "    # Create polar axes on top with transparent background\n",
    "    ax = fig.add_subplot(111, projection='polar')\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Normalize frame numbers to angles in radians\n",
    "    min_frame, max_frame = min(frames), max(frames)\n",
    "    theta = [2 * np.pi * ((frame - min_frame) / (max_frame - min_frame)) for frame in frames]\n",
    "\n",
    "    # Plot only markers (without connecting line)\n",
    "    ax.plot(theta, offsets, marker='o', linestyle='', color=color, markeredgecolor='black', markeredgewidth = 0.5, zorder=1)\n",
    "\n",
    "    # Set radial limits and tick marks (offset values from 0 to 100)\n",
    "    ax.set_rlim(0, 100)\n",
    "    ax.set_yticks([0, 20, 40, 60, 80, 100])\n",
    "    ax.set_rlabel_position(90)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "    # Set angular tick marks based on normalized frame numbers\n",
    "    num_ticks = 7\n",
    "    frame_ticks = np.linspace(min_frame, max_frame, num=num_ticks)\n",
    "    theta_ticks = [2 * np.pi * ((frame - min_frame) / (max_frame - min_frame)) for frame in frame_ticks]\n",
    "    labels = [str(int(frame + 1)) for frame in frame_ticks]\n",
    "    labels[0] = ''\n",
    "    labels[-1] = ''\n",
    "    ax.set_thetagrids(np.degrees(theta_ticks), labels=labels, color=COLOR_ANGULAR_AXIS_LABELS, fontsize=14, fontweight = 'bold')\n",
    "\n",
    "    r_max = ax.get_rmax() \n",
    "    for i in range(num_ticks - 1):\n",
    "        if i % 2 == 1:  \n",
    "            theta_start = theta_ticks[i]               \n",
    "            width = theta_ticks[i+1] - theta_ticks[i]     # Angular width of the sector\n",
    "            # Draw a bar (sector) from radius 0 to r_max with the given width.\n",
    "            ax.bar(theta_start, r_max, width=width, bottom=0,\n",
    "                color='#c4c4c4', alpha=0.3, edgecolor='none', zorder=0, align='edge')\n",
    "\n",
    "    # Style the radial (offset) tick labels\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_zorder(10)\n",
    "        label.set_fontweight('bold')\n",
    "        label.set_color(COLOR_RADIAL_AXIS_LABELS)\n",
    "        label.set_horizontalalignment('center')\n",
    "\n",
    "    # Add text annotation showing the frame range along the outer edge\n",
    "    angle = 0  # Corresponds to 0 degrees\n",
    "    r_out = ax.get_rmax() * 1.115\n",
    "    ax.text(angle, r_out, f\"{int(frame_ticks[0])}, {int(frame_ticks[-1] + 1)}\",\n",
    "            ha='center', va='center', color=COLOR_ANGULAR_AXIS_LABELS, fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Place the plot title above the plot area\n",
    "    ax.set_title(title, va='bottom', pad=20, fontsize=34, color=COLOR_TITLE, fontstyle='italic')\n",
    "\n",
    "    # Add custom axis titles as annotations (they sit outside the main plot box)\n",
    "    ax.text(np.radians(180), ax.get_rmax() * 1.2, ylabel,\n",
    "            ha='center', va='center', fontsize=20, color=COLOR_AXIS_TITLE, fontweight='bold', rotation=90)\n",
    "    ax.text(np.radians(270), ax.get_rmax() * 1.1, xlabel,\n",
    "            ha='center', va='center', fontsize=20, color=COLOR_AXIS_TITLE,fontweight='bold')\n",
    "\n",
    "    ax.grid(True)\n",
    "\n",
    "    return fig\n",
    "\n",
    "def plot_augmentation_summary(summary_file_path: str, title: str = 'Augmentation Summary', \n",
    "                            bar_color: str = 'gray') -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Read an augmentations summary text file and create a bar chart.\n",
    "    \n",
    "    The text file is expected to have a header line followed by lines in the format:\n",
    "        augmentation_name: count image(s) augmented\n",
    "    This function will ignore the header line and reformat augmentation names\n",
    "    (e.g., \"motion_blur\" becomes \"Motion Blur\") for the x-axis labels.\n",
    "    \n",
    "    The bar chart uses the same background image and formatting as the other plots.\n",
    "    \n",
    "    Args:\n",
    "        summary_file_path (str): Full path to the Augmentations Summary text file.\n",
    "        title (str): Title of the bar chart.\n",
    "        bar_color (str): Color for the bars.\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: Figure containing the bar chart.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    # Load the common background image\n",
    "    BG_IMAGE = plt.imread(r\"C:\\Users\\Jai\\Downloads\\Individual Project Folder\\yolov8-project\\dataset6\\BG_IMAGE2.png\")\n",
    "    \n",
    "    # Create figure and background axes\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax_bg = fig.add_axes([0, 0, 1, 1])\n",
    "    #ax_bg.set_facecolor('#e1f2f5')\n",
    "    ax_bg.imshow(BG_IMAGE, aspect='auto')\n",
    "\n",
    "    ax_bg.axis('off')\n",
    "    \n",
    "    # Create main axes with white background and grid styling\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=0.6, alpha=0.7)\n",
    "    \n",
    "    augmentation_names = []\n",
    "    counts = []\n",
    "    \n",
    "    with open(summary_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # Skip header lines if present\n",
    "            if not line or line.lower().startsWith(\"augmentation summary\"):\n",
    "                continue\n",
    "            # Expecting a colon to separate the augmentation name and the count info\n",
    "            if ':' in line:\n",
    "                parts = line.split(':', 1)\n",
    "                raw_name = parts[0].strip()\n",
    "                # Reformat name: replace underscores with spaces and title-case it\n",
    "                name = raw_name.replace('_', ' ').title()\n",
    "                # Extract the first number from the remainder of the line\n",
    "                match = re.search(r'\\d+', parts[1])\n",
    "                count = int(match.group()) if match else 0\n",
    "                augmentation_names.append(name)\n",
    "                counts.append(count)\n",
    "    \n",
    "    # List of pastel colours\n",
    "    colors = plt.cm.Pastel1(np.linspace(0, 1, len(augmentation_names)))\n",
    "\n",
    "    # Create bar chart\n",
    "    ax.bar(augmentation_names, counts, color=colors, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "    # Replace space in augmentation names with a new-line character\n",
    "    modified_labels = []\n",
    "    for label in augmentation_names:\n",
    "        label = label.replace(' ','\\n')\n",
    "        modified_labels.append(label)\n",
    "    \n",
    "    # Set title and axis labels with consistent formatting\n",
    "    ax.set_xlabel(\"Augmentation Type\", fontsize=20, fontweight=\"bold\", color=\"black\", labelpad=5)\n",
    "    ax.set_ylabel(\"Augmentation Count\", fontsize=20, fontweight=\"bold\", color=\"black\", labelpad=10)\n",
    "    ax.set_title(title, fontsize=34, fontweight=\"bold\", fontstyle=\"italic\", color=\"black\", pad=20)\n",
    "    ax.grid(False)\n",
    "    \n",
    "    # Enhance tick label appearance\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontsize(16)\n",
    "        label.set_fontweight(\"bold\")\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontsize(16)\n",
    "        label.set_fontweight(\"bold\")\n",
    "    ax.set_xticks(range(len(modified_labels)))\n",
    "    ax.set_xticklabels(modified_labels, rotation=45, ha='right')\n",
    "    \n",
    "    fig.subplots_adjust(bottom=0.4)\n",
    "\n",
    "    return fig\n",
    "\n",
    "def confusion_matrices() -> None:\n",
    "    \"\"\"\n",
    "    Create and save confusion matrix visualizations for different YOLOv8 models.\n",
    "    \n",
    "    Reads confusion matrix data from CSV files and generates heatmap visualizations\n",
    "    for YOLOv8n, YOLOv11n, and YOLOv12n models with custom colors and styling.\n",
    "    Saves the resulting figures as PNG files in the Results directory.\n",
    "    \"\"\"\n",
    "    # Define the list of confusion matrix file paths and corresponding model names\n",
    "    confusion_matrices = [CONFUSION_MATRIX_8, CONFUSION_MATRIX_11, CONFUSION_MATRIX_12]\n",
    "    model_names = [\"YOLOv8n\", \"YOLOv11n\", \"YOLOv12n\"]\n",
    "\n",
    "    # Loop through each confusion matrix\n",
    "    for i, confusion_matrix in enumerate(confusion_matrices):\n",
    "        # Read the confusion matrix data from the CSV file\n",
    "        # The first column is used as the row index\n",
    "        confusion_df = pd.read_csv(confusion_matrix, index_col=0)\n",
    "\n",
    "        # Convert the DataFrame to a NumPy array and ensure values are integers\n",
    "        conf_matrix = confusion_df.values.astype(int)\n",
    "\n",
    "        # Define class labels in the order they appear in the matrix\n",
    "        class_labels = [\"Satellite\", \"Envisat\", \"Hubble\", \"Falcon 9 F&S\"]\n",
    "\n",
    "        # Create a new figure with specific dimensions (width, height in inches)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "\n",
    "        # Select a specific color for each model for visual distinction\n",
    "        if i == 0:\n",
    "            hex_color = \"#13E7C4\"  # Teal color for YOLOv8n\n",
    "        elif i == 1:\n",
    "            hex_color = \"#E97132\"  # Orange color for YOLOv11n\n",
    "        else:\n",
    "            hex_color = \"#196B24\"  # Green color for YOLOv12n\n",
    "        \n",
    "        # Create a custom color gradient from white to the model's color\n",
    "        cmap = LinearSegmentedColormap.from_list('custom_color', ['white', hex_color])\n",
    "\n",
    "        # Generate the heatmap visualization\n",
    "        ax = sns.heatmap(\n",
    "            conf_matrix,          # The confusion matrix data\n",
    "            annot=True,           # Show the values in each cell\n",
    "            fmt='d',              # Format values as integers\n",
    "            cmap=cmap,            # Use our custom color gradient\n",
    "            xticklabels=class_labels,  # Labels for the x-axis (predicted classes)\n",
    "            yticklabels=class_labels   # Labels for the y-axis (actual classes)\n",
    "        )\n",
    "\n",
    "        # Add title and axis labels with custom formatting\n",
    "        plt.title(f\"Confusion Matrix - {model_names[i]}\", fontsize=24, fontweight=\"bold\", pad=20)\n",
    "        plt.xlabel(\"Predicted Label\", fontsize=16, fontweight=\"bold\", labelpad=10)\n",
    "        plt.ylabel(\"True Label\", fontsize=16, fontweight=\"bold\", labelpad=10)\n",
    "\n",
    "        # Format the tick labels to be bold and horizontal\n",
    "        plt.xticks(fontweight=\"bold\", rotation=0)\n",
    "        plt.yticks(fontweight=\"bold\", rotation=0)\n",
    "\n",
    "        # Adjust the layout to ensure all elements fit within the figure\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the figure to disk with a model-specific filename\n",
    "        save_path = os.path.join(DATASET_BASE,rf\"Results\\confusion_matrix_{model_names[i]}.png\")\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "# ============================================================\n",
    "# MAIN EXECUTION BLOCK\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Define folders for data sources\n",
    "    debris_folder = r\"C:\\Users\\Jai\\Downloads\\Individual Project Folder\\yolov8-project\\dataset5\\orbit_container_coordinates\"\n",
    "    container_folder = r\"C:\\Users\\Jai\\Downloads\\Individual Project Folder\\yolov8-project\\dataset5\\debris_tracking_container_coordinates\"\n",
    "    camera_folder = r\"C:\\Users\\Jai\\Downloads\\Individual Project Folder\\yolov8-project\\dataset5\\camera_container_coordinates\"\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Process and plot 3D coordinates for debris\n",
    "    # ------------------------------------------------------------\n",
    "    print(\"\\n===== PROCESSING DEBRIS COORDINATES =====\")\n",
    "    x_vals, y_vals, z_vals = load_coordinates(ORBIT_CONTAINER_COORDINATES)\n",
    "    debris_fig = plot_3d_scatter(x_vals, y_vals, z_vals,\n",
    "                                 title='Debris position relative to Earth',\n",
    "                                 marker_size=15, alpha=0.8)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Process and plot quaternions for debris orientation\n",
    "    # ------------------------------------------------------------\n",
    "    print(\"\\n===== PROCESSING DEBRIS ORIENTATIONS QUATERNIONS =====\")\n",
    "    w_vals, x_vals, y_vals, z_vals = load_debris_quaternion_coordinates(QUATERNION_COORDINATES)\n",
    "    debris_quaternion_fig = plot_3d_quaternion_scatter(w_vals, x_vals, y_vals, z_vals,\n",
    "                                                       title='Debris Orientation (Quaternion)',\n",
    "                                                       marker_size=15, alpha=0.8)\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    # Process and plot Euler for debris orientation\n",
    "    # ------------------------------------------------------------\n",
    "    print(\"\\n===== PROCESSING DEBRIS ORIENTATIONS EULER =====\")\n",
    "    roll_vals, pitch_vals, yaw_vals = load_coordinates(EULER_COORDINATES)\n",
    "    debris_euler_fig = plot_euler_angle_scatter(roll_vals, pitch_vals, yaw_vals,\n",
    "                                                title='Debris Orientation (Euler)',\n",
    "                                                marker_size=15, alpha=0.8)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Process and plot offset values for container\n",
    "    # ------------------------------------------------------------\n",
    "    print(\"\\n===== PROCESSING CONTAINER OFFSETS =====\")\n",
    "    container_frames, container_offsets = load_offset_values(DEBRIS_TRACKING_CONTAINER_COORDINATES)\n",
    "    container_fig = plot_offset_values(container_frames, container_offsets,\n",
    "                                       title='Camera position relative to Debris',\n",
    "                                       color='gray',\n",
    "                                       ylabel=\"Position on 'Debris Tracking Geometry'\",\n",
    "                                       xlabel=\"Image Number\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Process and plot offset values for camera\n",
    "    # ------------------------------------------------------------\n",
    "    print(\"\\n===== PROCESSING CAMERA OFFSETS =====\")\n",
    "    camera_frames, camera_offsets = load_offset_values(CAMERA_CONTAINER_COORDINATES)\n",
    "    camera_fig = plot_offset_values(camera_frames, camera_offsets,\n",
    "                                    title='Camera Offset Values',\n",
    "                                    color='gray',\n",
    "                                    ylabel=\"Position on 'Camera Geometry'\",\n",
    "                                    xlabel=\"Image Number\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Process and plot augmentation summary bar chart\n",
    "    # ------------------------------------------------------------\n",
    "    print(\"\\n===== PROCESSING AUGMENTATION SUMMARY =====\")\n",
    "    augmentation_summary_file = AUGMENTATION_SUMMARY\n",
    "    augmentation_fig = plot_augmentation_summary(augmentation_summary_file,\n",
    "                                                 title=\"Augmentation Summary\",\n",
    "                                                 bar_color='gray')\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    # Plot and save confusion matrix\n",
    "    # ------------------------------------------------------------\n",
    "    confusion_matrices()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Save plots as image files (with 300 dpi resolution)\n",
    "    # ------------------------------------------------------------\n",
    "    debris_fig.savefig(os.path.join(ORBIT_CONTAINER_COORDINATES, \"Orbit Container Plot.png\"), dpi=300, bbox_inches='tight')\n",
    "    container_fig.savefig(os.path.join(DEBRIS_TRACKING_CONTAINER_COORDINATES, \"Debris Tracking Container Plot.png\"), dpi=300)\n",
    "    camera_fig.savefig(os.path.join(CAMERA_CONTAINER_COORDINATES, \"camera_container_plot.png\"), dpi=300)\n",
    "    debris_quaternion_fig.savefig(os.path.join(QUATERNION_COORDINATES, \"Debris Orientation Quaternion.png\"), dpi=300)\n",
    "    debris_euler_fig.savefig(os.path.join(EULER_COORDINATES, \"Debris Orientation Euler.png\"), dpi=300)\n",
    "    augmentation_fig.savefig(os.path.join(os.path.dirname(augmentation_summary_file), \"Augmentation Summary Plot.png\"), dpi=300)\n",
    "\n",
    "    # Adjust layout and display all figures\n",
    "    plt.tight_layout()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MobileNetV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
